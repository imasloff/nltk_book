{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "033ee962",
   "metadata": {},
   "source": [
    "# 1   Supervised Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36061e5b",
   "metadata": {},
   "source": [
    "## 1.1   Gender Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "50dc78ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_letter': 'S', 'last_letter': 'k', 'length': 5}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk, re\n",
    "def gender_features(word):\n",
    "    vowels = r'[aeiouAEIOU]'\n",
    "    return {\n",
    "        'first_letter': word[0], \n",
    "        'last_letter': word[-1], \n",
    "        'length': len(word), \n",
    "    }\n",
    "gender_features('Shrek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "82741774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "[(name, 'female') for name in names.words('female.txt')])\n",
    "import random\n",
    "random.shuffle(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ac91ff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e967ebac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'male'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(gender_features('Neo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d5e602cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(gender_features('Trinity'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0a2668ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3c966c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     34.6 : 1.0\n",
      "             last_letter = 'k'              male : female =     30.9 : 1.0\n",
      "             last_letter = 'f'              male : female =     16.0 : 1.0\n",
      "             last_letter = 'p'              male : female =     11.9 : 1.0\n",
      "             last_letter = 'v'              male : female =     11.2 : 1.0\n",
      "             last_letter = 'd'              male : female =      9.9 : 1.0\n",
      "             last_letter = 'o'              male : female =      9.3 : 1.0\n",
      "             last_letter = 'm'              male : female =      8.9 : 1.0\n",
      "             last_letter = 'r'              male : female =      6.7 : 1.0\n",
      "             last_letter = 'g'              male : female =      5.5 : 1.0\n",
      "            first_letter = 'W'              male : female =      4.7 : 1.0\n",
      "             last_letter = 'w'              male : female =      4.5 : 1.0\n",
      "             last_letter = 's'              male : female =      4.3 : 1.0\n",
      "             last_letter = 't'              male : female =      4.1 : 1.0\n",
      "             last_letter = 'z'              male : female =      4.0 : 1.0\n",
      "             last_letter = 'b'              male : female =      3.9 : 1.0\n",
      "             last_letter = 'i'            female : male   =      3.6 : 1.0\n",
      "             last_letter = 'u'              male : female =      3.6 : 1.0\n",
      "            first_letter = 'U'              male : female =      2.8 : 1.0\n",
      "            first_letter = 'Q'              male : female =      2.6 : 1.0\n",
      "            first_letter = 'X'              male : female =      2.3 : 1.0\n",
      "                  length = 2                male : female =      2.3 : 1.0\n",
      "            first_letter = 'H'              male : female =      2.2 : 1.0\n",
      "            first_letter = 'K'            female : male   =      2.2 : 1.0\n",
      "             last_letter = 'n'              male : female =      2.1 : 1.0\n",
      "                  length = 3                male : female =      2.0 : 1.0\n",
      "            first_letter = 'Z'              male : female =      1.8 : 1.0\n",
      "             last_letter = 'e'            female : male   =      1.8 : 1.0\n",
      "             last_letter = 'l'              male : female =      1.8 : 1.0\n",
      "            first_letter = 'L'            female : male   =      1.7 : 1.0\n",
      "                  length = 15               male : female =      1.7 : 1.0\n",
      "             last_letter = 'j'              male : female =      1.7 : 1.0\n",
      "             last_letter = 'x'              male : female =      1.7 : 1.0\n",
      "            first_letter = 'C'            female : male   =      1.7 : 1.0\n",
      "            first_letter = 'T'              male : female =      1.5 : 1.0\n",
      "                  length = 10             female : male   =      1.5 : 1.0\n",
      "             last_letter = 'h'              male : female =      1.5 : 1.0\n",
      "            first_letter = 'P'              male : female =      1.4 : 1.0\n",
      "            first_letter = 'M'            female : male   =      1.4 : 1.0\n",
      "                  length = 9              female : male   =      1.4 : 1.0\n",
      "            first_letter = 'R'              male : female =      1.3 : 1.0\n",
      "            first_letter = 'Y'              male : female =      1.3 : 1.0\n",
      "            first_letter = 'S'              male : female =      1.3 : 1.0\n",
      "            first_letter = 'O'              male : female =      1.3 : 1.0\n",
      "            first_letter = 'G'              male : female =      1.3 : 1.0\n",
      "            first_letter = 'E'            female : male   =      1.2 : 1.0\n",
      "            first_letter = 'V'            female : male   =      1.2 : 1.0\n",
      "            first_letter = 'N'            female : male   =      1.2 : 1.0\n",
      "             last_letter = 'y'              male : female =      1.2 : 1.0\n",
      "                  length = 11             female : male   =      1.2 : 1.0\n",
      "            first_letter = 'A'            female : male   =      1.2 : 1.0\n",
      "            first_letter = 'D'            female : male   =      1.2 : 1.0\n",
      "                  length = 4                male : female =      1.2 : 1.0\n",
      "            first_letter = 'J'            female : male   =      1.2 : 1.0\n",
      "            first_letter = 'B'              male : female =      1.2 : 1.0\n",
      "                  length = 7              female : male   =      1.1 : 1.0\n",
      "            first_letter = 'I'            female : male   =      1.1 : 1.0\n",
      "                  length = 8              female : male   =      1.1 : 1.0\n",
      "                  length = 12               male : female =      1.1 : 1.0\n",
      "                  length = 5              female : male   =      1.1 : 1.0\n",
      "                  length = 6                male : female =      1.1 : 1.0\n",
      "            first_letter = 'F'            female : male   =      1.0 : 1.0\n",
      "                  length = 13               male : female =      1.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e7885cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import apply_features\n",
    "train_set = apply_features(gender_features, labeled_names[500:])\n",
    "test_set = apply_features(gender_features, labeled_names[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771034dd",
   "metadata": {},
   "source": [
    "## 1.2   Choosing The Right Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f0082c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features2(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "799f23e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_letter': 'j',\n",
       " 'last_letter': 'n',\n",
       " 'count(a)': 0,\n",
       " 'has(a)': False,\n",
       " 'count(b)': 0,\n",
       " 'has(b)': False,\n",
       " 'count(c)': 0,\n",
       " 'has(c)': False,\n",
       " 'count(d)': 0,\n",
       " 'has(d)': False,\n",
       " 'count(e)': 0,\n",
       " 'has(e)': False,\n",
       " 'count(f)': 0,\n",
       " 'has(f)': False,\n",
       " 'count(g)': 0,\n",
       " 'has(g)': False,\n",
       " 'count(h)': 1,\n",
       " 'has(h)': True,\n",
       " 'count(i)': 0,\n",
       " 'has(i)': False,\n",
       " 'count(j)': 1,\n",
       " 'has(j)': True,\n",
       " 'count(k)': 0,\n",
       " 'has(k)': False,\n",
       " 'count(l)': 0,\n",
       " 'has(l)': False,\n",
       " 'count(m)': 0,\n",
       " 'has(m)': False,\n",
       " 'count(n)': 1,\n",
       " 'has(n)': True,\n",
       " 'count(o)': 1,\n",
       " 'has(o)': True,\n",
       " 'count(p)': 0,\n",
       " 'has(p)': False,\n",
       " 'count(q)': 0,\n",
       " 'has(q)': False,\n",
       " 'count(r)': 0,\n",
       " 'has(r)': False,\n",
       " 'count(s)': 0,\n",
       " 'has(s)': False,\n",
       " 'count(t)': 0,\n",
       " 'has(t)': False,\n",
       " 'count(u)': 0,\n",
       " 'has(u)': False,\n",
       " 'count(v)': 0,\n",
       " 'has(v)': False,\n",
       " 'count(w)': 0,\n",
       " 'has(w)': False,\n",
       " 'count(x)': 0,\n",
       " 'has(x)': False,\n",
       " 'count(y)': 0,\n",
       " 'has(y)': False,\n",
       " 'count(z)': 0,\n",
       " 'has(z)': False}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features2('John') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1a3df904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.752\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(gender_features2(n), gender) for (n, gender) in labeled_names]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a144e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = labeled_names[1500:]\n",
    "devtest_names = labeled_names[500:1500]\n",
    "test_names = labeled_names[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c28cbb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.762\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
    "devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
    "test_set = [(gender_features(n), gender) for (n, gender) in test_names]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, devtest_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2047ecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for (name, tag) in devtest_names:\n",
    "    guess = classifier.classify(gender_features(name))\n",
    "    if guess != tag:\n",
    "        errors.append( (tag, guess, name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5d35bf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct=female   guess=male     name=Adel                          \n",
      "correct=female   guess=male     name=Adrien                        \n",
      "correct=female   guess=male     name=Ag                            \n",
      "correct=female   guess=male     name=Alyss                         \n",
      "correct=female   guess=male     name=Amber                         \n",
      "correct=female   guess=male     name=Ardelis                       \n",
      "correct=female   guess=male     name=Ashlen                        \n",
      "correct=female   guess=male     name=Bab                           \n",
      "correct=female   guess=male     name=Babs                          \n",
      "correct=female   guess=male     name=Beret                         \n",
      "correct=female   guess=male     name=Beth                          \n",
      "correct=female   guess=male     name=Bird                          \n",
      "correct=female   guess=male     name=Brear                         \n",
      "correct=female   guess=male     name=Brook                         \n",
      "correct=female   guess=male     name=Brooks                        \n",
      "correct=female   guess=male     name=Bryn                          \n",
      "correct=female   guess=male     name=Cam                           \n",
      "correct=female   guess=male     name=Chad                          \n",
      "correct=female   guess=male     name=Charlot                       \n",
      "correct=female   guess=male     name=Clair                         \n",
      "correct=female   guess=male     name=Cleo                          \n",
      "correct=female   guess=male     name=Consuelo                      \n",
      "correct=female   guess=male     name=Coriss                        \n",
      "correct=female   guess=male     name=Cyb                           \n",
      "correct=female   guess=male     name=Dallas                        \n",
      "correct=female   guess=male     name=Denys                         \n",
      "correct=female   guess=male     name=Doloritas                     \n",
      "correct=female   guess=male     name=Dorcas                        \n",
      "correct=female   guess=male     name=Edin                          \n",
      "correct=female   guess=male     name=Ellen                         \n",
      "correct=female   guess=male     name=Emlyn                         \n",
      "correct=female   guess=male     name=Emmalynn                      \n",
      "correct=female   guess=male     name=Eryn                          \n",
      "correct=female   guess=male     name=Ester                         \n",
      "correct=female   guess=male     name=Ethelind                      \n",
      "correct=female   guess=male     name=Fallon                        \n",
      "correct=female   guess=male     name=Fran                          \n",
      "correct=female   guess=male     name=Gay                           \n",
      "correct=female   guess=male     name=Gennifer                      \n",
      "correct=female   guess=male     name=Gladis                        \n",
      "correct=female   guess=male     name=Glyn                          \n",
      "correct=female   guess=male     name=Glynnis                       \n",
      "correct=female   guess=male     name=Hannis                        \n",
      "correct=female   guess=male     name=Hedwig                        \n",
      "correct=female   guess=male     name=Helen                         \n",
      "correct=female   guess=male     name=Hildagard                     \n",
      "correct=female   guess=male     name=Honey                         \n",
      "correct=female   guess=male     name=Hyacinth                      \n",
      "correct=female   guess=male     name=Imogen                        \n",
      "correct=female   guess=male     name=Imojean                       \n",
      "correct=female   guess=male     name=Ivy                           \n",
      "correct=female   guess=male     name=Izabel                        \n",
      "correct=female   guess=male     name=Jo-Ann                        \n",
      "correct=female   guess=male     name=Jordan                        \n",
      "correct=female   guess=male     name=Lillis                        \n",
      "correct=female   guess=male     name=Lou                           \n",
      "correct=female   guess=male     name=Margalit                      \n",
      "correct=female   guess=male     name=Marit                         \n",
      "correct=female   guess=male     name=Mellicent                     \n",
      "correct=female   guess=male     name=Meris                         \n",
      "correct=female   guess=male     name=Myriam                        \n",
      "correct=female   guess=male     name=Nan                           \n",
      "correct=female   guess=male     name=Nariko                        \n",
      "correct=female   guess=male     name=Norean                        \n",
      "correct=female   guess=male     name=Olwen                         \n",
      "correct=female   guess=male     name=Quentin                       \n",
      "correct=female   guess=male     name=Ragnhild                      \n",
      "correct=female   guess=male     name=Raven                         \n",
      "correct=female   guess=male     name=Ray                           \n",
      "correct=female   guess=male     name=Robbyn                        \n",
      "correct=female   guess=male     name=Rosabel                       \n",
      "correct=female   guess=male     name=Rosario                       \n",
      "correct=female   guess=male     name=Roselin                       \n",
      "correct=female   guess=male     name=Rosy                          \n",
      "correct=female   guess=male     name=Row                           \n",
      "correct=female   guess=male     name=Roz                           \n",
      "correct=female   guess=male     name=Ruby                          \n",
      "correct=female   guess=male     name=Ruth                          \n",
      "correct=female   guess=male     name=Scarlett                      \n",
      "correct=female   guess=male     name=Shir                          \n",
      "correct=female   guess=male     name=Sigrid                        \n",
      "correct=female   guess=male     name=Suzan                         \n",
      "correct=female   guess=male     name=Sydel                         \n",
      "correct=female   guess=male     name=Tammy                         \n",
      "correct=female   guess=male     name=Tatum                         \n",
      "correct=female   guess=male     name=Teriann                       \n",
      "correct=female   guess=male     name=Tessy                         \n",
      "correct=female   guess=male     name=Tiff                          \n",
      "correct=female   guess=male     name=Timmy                         \n",
      "correct=female   guess=male     name=Tommy                         \n",
      "correct=female   guess=male     name=Tony                          \n",
      "correct=female   guess=male     name=Umeko                         \n",
      "correct=female   guess=male     name=Velvet                        \n",
      "correct=female   guess=male     name=Vivian                        \n",
      "correct=female   guess=male     name=Willow                        \n",
      "correct=female   guess=male     name=Wynnie                        \n",
      "correct=male     guess=female   name=Aaron                         \n",
      "correct=male     guess=female   name=Abdel                         \n",
      "correct=male     guess=female   name=Ace                           \n",
      "correct=male     guess=female   name=Addie                         \n",
      "correct=male     guess=female   name=Adnan                         \n",
      "correct=male     guess=female   name=Adolphe                       \n",
      "correct=male     guess=female   name=Aguste                        \n",
      "correct=male     guess=female   name=Algernon                      \n",
      "correct=male     guess=female   name=Ali                           \n",
      "correct=male     guess=female   name=Alix                          \n",
      "correct=male     guess=female   name=Andie                         \n",
      "correct=male     guess=female   name=Arron                         \n",
      "correct=male     guess=female   name=Arvin                         \n",
      "correct=male     guess=female   name=Averell                       \n",
      "correct=male     guess=female   name=Baillie                       \n",
      "correct=male     guess=female   name=Baily                         \n",
      "correct=male     guess=female   name=Barclay                       \n",
      "correct=male     guess=female   name=Bartie                        \n",
      "correct=male     guess=female   name=Berkeley                      \n",
      "correct=male     guess=female   name=Billie                        \n",
      "correct=male     guess=female   name=Binky                         \n",
      "correct=male     guess=female   name=Bobby                         \n",
      "correct=male     guess=female   name=Bruce                         \n",
      "correct=male     guess=female   name=Caldwell                      \n",
      "correct=male     guess=female   name=Carlin                        \n",
      "correct=male     guess=female   name=Carson                        \n",
      "correct=male     guess=female   name=Chan                          \n",
      "correct=male     guess=female   name=Chase                         \n",
      "correct=male     guess=female   name=Christoph                     \n",
      "correct=male     guess=female   name=Clayton                       \n",
      "correct=male     guess=female   name=Clyde                         \n",
      "correct=male     guess=female   name=Cody                          \n",
      "correct=male     guess=female   name=Cole                          \n",
      "correct=male     guess=female   name=Coleman                       \n",
      "correct=male     guess=female   name=Cory                          \n",
      "correct=male     guess=female   name=Dana                          \n",
      "correct=male     guess=female   name=Danie                         \n",
      "correct=male     guess=female   name=Daniel                        \n",
      "correct=male     guess=female   name=Daryl                         \n",
      "correct=male     guess=female   name=Davie                         \n",
      "correct=male     guess=female   name=Davy                          \n",
      "correct=male     guess=female   name=Demetre                       \n",
      "correct=male     guess=female   name=Derby                         \n",
      "correct=male     guess=female   name=Derrol                        \n",
      "correct=male     guess=female   name=Devon                         \n",
      "correct=male     guess=female   name=Dickie                        \n",
      "correct=male     guess=female   name=Dietrich                      \n",
      "correct=male     guess=female   name=Donal                         \n",
      "correct=male     guess=female   name=Donovan                       \n",
      "correct=male     guess=female   name=Dwayne                        \n",
      "correct=male     guess=female   name=Dyson                         \n",
      "correct=male     guess=female   name=Ellsworth                     \n",
      "correct=male     guess=female   name=Errol                         \n",
      "correct=male     guess=female   name=Ezra                          \n",
      "correct=male     guess=female   name=Farley                        \n",
      "correct=male     guess=female   name=Felix                         \n",
      "correct=male     guess=female   name=Ferdy                         \n",
      "correct=male     guess=female   name=Frederich                     \n",
      "correct=male     guess=female   name=Gabe                          \n",
      "correct=male     guess=female   name=Grace                         \n",
      "correct=male     guess=female   name=Grove                         \n",
      "correct=male     guess=female   name=Hari                          \n",
      "correct=male     guess=female   name=Hymie                         \n",
      "correct=male     guess=female   name=Iggie                         \n",
      "correct=male     guess=female   name=Ikey                          \n",
      "correct=male     guess=female   name=Jameson                       \n",
      "correct=male     guess=female   name=Jamey                         \n",
      "correct=male     guess=female   name=Jason                         \n",
      "correct=male     guess=female   name=Jean-Christophe               \n",
      "correct=male     guess=female   name=Jeramie                       \n",
      "correct=male     guess=female   name=Jeremy                        \n",
      "correct=male     guess=female   name=Jeromy                        \n",
      "correct=male     guess=female   name=Jimmie                        \n",
      "correct=male     guess=female   name=Jodi                          \n",
      "correct=male     guess=female   name=Jodie                         \n",
      "correct=male     guess=female   name=Jonathon                      \n",
      "correct=male     guess=female   name=Judith                        \n",
      "correct=male     guess=female   name=Kalle                         \n",
      "correct=male     guess=female   name=Kalman                        \n",
      "correct=male     guess=female   name=Kalvin                        \n",
      "correct=male     guess=female   name=Kane                          \n",
      "correct=male     guess=female   name=Karel                         \n",
      "correct=male     guess=female   name=Karsten                       \n",
      "correct=male     guess=female   name=Kelley                        \n",
      "correct=male     guess=female   name=Kenny                         \n",
      "correct=male     guess=female   name=Kory                          \n",
      "correct=male     guess=female   name=Lawrence                      \n",
      "correct=male     guess=female   name=Lawson                        \n",
      "correct=male     guess=female   name=Layton                        \n",
      "correct=male     guess=female   name=Linoel                        \n",
      "correct=male     guess=female   name=Luke                          \n",
      "correct=male     guess=female   name=Lynn                          \n",
      "correct=male     guess=female   name=Marlon                        \n",
      "correct=male     guess=female   name=Marshall                      \n",
      "correct=male     guess=female   name=Marve                         \n",
      "correct=male     guess=female   name=Meade                         \n",
      "correct=male     guess=female   name=Melvin                        \n",
      "correct=male     guess=female   name=Mendel                        \n",
      "correct=male     guess=female   name=Meredeth                      \n",
      "correct=male     guess=female   name=Merrill                       \n",
      "correct=male     guess=female   name=Micky                         \n",
      "correct=male     guess=female   name=Montague                      \n",
      "correct=male     guess=female   name=Morley                        \n",
      "correct=male     guess=female   name=Mose                          \n",
      "correct=male     guess=female   name=Murdoch                       \n",
      "correct=male     guess=female   name=Mustafa                       \n",
      "correct=male     guess=female   name=Myron                         \n",
      "correct=male     guess=female   name=Nathanil                      \n",
      "correct=male     guess=female   name=Neale                         \n",
      "correct=male     guess=female   name=Nealy                         \n",
      "correct=male     guess=female   name=Nolan                         \n",
      "correct=male     guess=female   name=Obadiah                       \n",
      "correct=male     guess=female   name=Odie                          \n",
      "correct=male     guess=female   name=Pate                          \n",
      "correct=male     guess=female   name=Peirce                        \n",
      "correct=male     guess=female   name=Pembroke                      \n",
      "correct=male     guess=female   name=Percy                         \n",
      "correct=male     guess=female   name=Perry                         \n",
      "correct=male     guess=female   name=Randy                         \n",
      "correct=male     guess=female   name=Ravi                          \n",
      "correct=male     guess=female   name=Ricky                         \n",
      "correct=male     guess=female   name=Rikki                         \n",
      "correct=male     guess=female   name=Rocky                         \n",
      "correct=male     guess=female   name=Rube                          \n",
      "correct=male     guess=female   name=Salomone                      \n",
      "correct=male     guess=female   name=Saundra                       \n",
      "correct=male     guess=female   name=Scotty                        \n",
      "correct=male     guess=female   name=Serge                         \n",
      "correct=male     guess=female   name=Skippy                        \n",
      "correct=male     guess=female   name=Slade                         \n",
      "correct=male     guess=female   name=Stanleigh                     \n",
      "correct=male     guess=female   name=Stevie                        \n",
      "correct=male     guess=female   name=Terri                         \n",
      "correct=male     guess=female   name=Thane                         \n",
      "correct=male     guess=female   name=Tobe                          \n",
      "correct=male     guess=female   name=Torrence                      \n",
      "correct=male     guess=female   name=Trace                         \n",
      "correct=male     guess=female   name=Tuckie                        \n",
      "correct=male     guess=female   name=Valentine                     \n",
      "correct=male     guess=female   name=Vassili                       \n",
      "correct=male     guess=female   name=Verney                        \n",
      "correct=male     guess=female   name=Vite                          \n"
     ]
    }
   ],
   "source": [
    "for (tag, guess, name) in sorted(errors):\n",
    "    print('correct={:<8} guess={:<8s} name={:<30}'.format(tag, guess, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "824e3b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    return {'suffix1': word[-1:], 'suffix2': word[-2:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "040296be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.774\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
    "devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3801a8",
   "metadata": {},
   "source": [
    "## 1.3   Document Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5bb354ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "91fad544",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "word_features = list(all_words)[:2000]\n",
    "\n",
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9f51b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6f1bdba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "66c63205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "   contains(outstanding) = True              pos : neg    =     10.9 : 1.0\n",
      "         contains(mulan) = True              pos : neg    =      8.4 : 1.0\n",
      "        contains(seagal) = True              neg : pos    =      7.8 : 1.0\n",
      "   contains(wonderfully) = True              pos : neg    =      7.5 : 1.0\n",
      "         contains(damon) = True              pos : neg    =      6.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45c4fdd",
   "metadata": {},
   "source": [
    "## 1.4   Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "99073df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "suffix_fdist = nltk.FreqDist()\n",
    "for word in brown.words():\n",
    "    word = word.lower()\n",
    "    suffix_fdist[word[-1:]] += 1\n",
    "    suffix_fdist[word[-2:]] += 1\n",
    "    suffix_fdist[word[-3:]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9ca519ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', ',', '.', 's', 'd', 't', 'he', 'n', 'a', 'of', 'the', 'y', 'r', 'to', 'in', 'f', 'o', 'ed', 'nd', 'is', 'on', 'l', 'g', 'and', 'ng', 'er', 'as', 'ing', 'h', 'at', 'es', 'or', 're', 'it', '``', 'an', \"''\", 'm', ';', 'i', 'ly', 'ion', 'en', 'al', '?', 'nt', 'be', 'hat', 'st', 'his', 'th', 'll', 'le', 'ce', 'by', 'ts', 'me', 've', \"'\", 'se', 'ut', 'was', 'for', 'ent', 'ch', 'k', 'w', 'ld', '`', 'rs', 'ted', 'ere', 'her', 'ne', 'ns', 'ith', 'ad', 'ry', ')', '(', 'te', '--', 'ay', 'ty', 'ot', 'p', 'nce', \"'s\", 'ter', 'om', 'ss', ':', 'we', 'are', 'c', 'ers', 'uld', 'had', 'so', 'ey']\n"
     ]
    }
   ],
   "source": [
    "common_suffixes = [suffix for (suffix, count) in suffix_fdist.most_common(100)]\n",
    "print(common_suffixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "df149f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_features(word):\n",
    "    features = {}\n",
    "    for suffix in common_suffixes:\n",
    "        features['endswith({})'.format(suffix)] = word.lower().endswith(suffix)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e99c3c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_words = brown.tagged_words(categories='news')\n",
    "featuresets = [(pos_features(n), g) for (n,g) in tagged_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "957cec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "51783e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6270512182993535"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = nltk.DecisionTreeClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "03a831b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NNS'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(pos_features('cats'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7692f58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if endswith(the) == False: \n",
      "  if endswith(,) == False: \n",
      "    if endswith(s) == False: \n",
      "      if endswith(.) == False: return '.'\n",
      "      if endswith(.) == True: return '.'\n",
      "    if endswith(s) == True: \n",
      "      if endswith(is) == False: return 'PP$'\n",
      "      if endswith(is) == True: return 'BEZ'\n",
      "  if endswith(,) == True: return ','\n",
      "if endswith(the) == True: return 'AT'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classifier.pseudocode(depth=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2a37c3",
   "metadata": {},
   "source": [
    "## 1.5   Exploiting Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "46df78cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_features(sentence, i):\n",
    "    features = {\"suffix(1)\": sentence[i][-1:],\n",
    "                \"suffix(2)\": sentence[i][-2:],\n",
    "                \"suffix(3)\": sentence[i][-3:]}\n",
    "    if i == 0:\n",
    "        features[\"prev-word\"] = \"<START>\"\n",
    "    else:\n",
    "        features[\"prev-word\"] = sentence[i-1]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fed82cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'suffix(1)': 'n', 'suffix(2)': 'on', 'suffix(3)': 'ion', 'prev-word': 'an'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_features(brown.sents()[0], 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9b60b7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7891596220785678"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sents = brown.tagged_sents(categories='news')\n",
    "featuresets = []\n",
    "for tagged_sent in tagged_sents:\n",
    "    untagged_sent = nltk.tag.untag(tagged_sent)\n",
    "    for i, (word, tag) in enumerate(tagged_sent):\n",
    "        featuresets.append( (pos_features(untagged_sent, i), tag) )\n",
    "\n",
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0114cf9",
   "metadata": {},
   "source": [
    "## 1.6   Sequence Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0be023e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_features(sentence, i, history):\n",
    "    features = {\"suffix(1)\": sentence[i][-1:],\n",
    "                \"suffix(2)\": sentence[i][-2:],\n",
    "                \"suffix(3)\": sentence[i][-3:]}\n",
    "    if i == 0:\n",
    "        features[\"prev-word\"] = \"<START>\"\n",
    "        features[\"prev-tag\"] = \"<START>\"\n",
    "    else:\n",
    "        features[\"prev-word\"] = sentence[i-1]\n",
    "        features[\"prev-tag\"] = history[i-1]\n",
    "    return features\n",
    "\n",
    "class ConsecutivePosTagger(nltk.TaggerI):\n",
    "\n",
    "    def __init__(self, train_sents):\n",
    "        train_set = []\n",
    "        for tagged_sent in train_sents:\n",
    "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
    "            history = []\n",
    "            for i, (word, tag) in enumerate(tagged_sent):\n",
    "                featureset = pos_features(untagged_sent, i, history)\n",
    "                train_set.append( (featureset, tag) )\n",
    "                history.append(tag)\n",
    "        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "    def tag(self, sentence):\n",
    "        history = []\n",
    "        for i, word in enumerate(sentence):\n",
    "            featureset = pos_features(sentence, i, history)\n",
    "            tag = self.classifier.classify(featureset)\n",
    "            history.append(tag)\n",
    "        return zip(sentence, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6f25b818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7980528511821975\n"
     ]
    }
   ],
   "source": [
    "tagged_sents = brown.tagged_sents(categories='news')\n",
    "size = int(len(tagged_sents) * 0.1)\n",
    "train_sents, test_sents = tagged_sents[size:], tagged_sents[:size]\n",
    "tagger = ConsecutivePosTagger(train_sents)\n",
    "print(tagger.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77506d64",
   "metadata": {},
   "source": [
    "## 1.7   Other Methods for Sequence Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef253d41",
   "metadata": {},
   "source": [
    "# 2   Further Examples of Supervised Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d4f151",
   "metadata": {},
   "source": [
    "## 2.1   Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "369e3ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = nltk.corpus.treebank_raw.sents()\n",
    "tokens = []\n",
    "boundaries = set()\n",
    "offset = 0\n",
    "for sent in sents:\n",
    "    tokens.extend(sent)\n",
    "    offset += len(sent)\n",
    "    boundaries.add(offset-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d3544b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def punct_features(tokens, i):\n",
    "    return {'next-word-capitalized': tokens[i+1][0].isupper(),\n",
    "            'prev-word': tokens[i-1].lower(),\n",
    "            'punct': tokens[i],\n",
    "            'prev-word-is-one-char': len(tokens[i-1]) == 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3fab7f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(punct_features(tokens, i), (i in boundaries))\n",
    "               for i in range(1, len(tokens)-1)\n",
    "               if tokens[i] in '.?!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a935145c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.936026936026936"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cc4182d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_sentences(words):\n",
    "    start = 0\n",
    "    sents = []\n",
    "    for i, word in enumerate(words):\n",
    "        if word in '.?!' and classifier.classify(punct_features(words, i)) == True:\n",
    "            sents.append(words[start:i+1])\n",
    "            start = i+1\n",
    "    if start < len(words):\n",
    "        sents.append(words[start:])\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fa7e47eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = nltk.corpus.nps_chat.xml_posts()[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "69ed555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dialogue_act_features(post):\n",
    "    features = {}\n",
    "    for word in nltk.word_tokenize(post):\n",
    "        features['contains({})'.format(word.lower())] = True\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "71645259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.667\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(dialogue_act_features(post.text), post.get('class'))\n",
    "               for post in posts]\n",
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0de5dc",
   "metadata": {},
   "source": [
    "## 2.3   Recognizing Textual Entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1d4a6f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rte to\n",
      "[nltk_data]     C:\\Users\\ivanm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rte is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"rte\")\n",
    "def rte_features(rtepair):\n",
    "    extractor = nltk.RTEFeatureExtractor(rtepair)\n",
    "    features = {}\n",
    "    features['word_overlap'] = len(extractor.overlap('word'))\n",
    "    features['word_hyp_extra'] = len(extractor.hyp_extra('word'))\n",
    "    features['ne_overlap'] = len(extractor.overlap('ne'))\n",
    "    features['ne_hyp_extra'] = len(extractor.hyp_extra('ne'))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c545b3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SCO', 'representing', 'together', 'central', 'meeting', 'Organisation', 'association', 'operation', 'Shanghai', 'Parviz', 'China', 'former', 'was', 'republics', 'fledgling', 'fight', 'Co', 'Asia', 'terrorism.', 'binds', 'Russia', 'Davudi', 'Soviet', 'at', 'that', 'Iran', 'four'}\n"
     ]
    }
   ],
   "source": [
    "rtepair = nltk.corpus.rte.pairs(['rte3_dev.xml'])[33]\n",
    "extractor = nltk.RTEFeatureExtractor(rtepair)\n",
    "print(extractor.text_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3848cc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'China', 'SCO.', 'member'}\n"
     ]
    }
   ],
   "source": [
    "print(extractor.hyp_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "aca948f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(extractor.overlap('word'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f4dd3fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'China'}\n"
     ]
    }
   ],
   "source": [
    "print(extractor.overlap('ne'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d737b170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'member'}\n"
     ]
    }
   ],
   "source": [
    "print(extractor.hyp_extra('word'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c076b59",
   "metadata": {},
   "source": [
    "## 2.4   Scaling Up to Large Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23bd821",
   "metadata": {},
   "source": [
    "# 3   Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16cf406",
   "metadata": {},
   "source": [
    "## 3.1   The Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a39620d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from nltk.corpus import brown\n",
    "tagged_sents = list(brown.tagged_sents(categories='news'))\n",
    "random.shuffle(tagged_sents)\n",
    "size = int(len(tagged_sents) * 0.1)\n",
    "train_set, test_set = tagged_sents[size:], tagged_sents[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "847fe325",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ids = brown.fileids(categories='news')\n",
    "size = int(len(file_ids) * 0.1)\n",
    "train_set = brown.tagged_sents(file_ids[size:])\n",
    "test_set = brown.tagged_sents(file_ids[:size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7e522761",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = brown.tagged_sents(categories='news')\n",
    "test_set = brown.tagged_sents(categories='fiction')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4f31aa",
   "metadata": {},
   "source": [
    "## 3.2   Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8f18cb80",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-c4133f350263>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNaiveBayesClassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy: {:4.2f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\classify\\naivebayes.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(cls, labeled_featuresets, estimator)\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;31m# Count up how many times each feature value occurred, given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[1;31m# the label and featurename.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m             \u001b[0mlabel_freqdist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print('Accuracy: {:4.2f}'.format(nltk.classify.accuracy(classifier, test_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf72b0c2",
   "metadata": {},
   "source": [
    "## 3.3   Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd07cef7",
   "metadata": {},
   "source": [
    "## 3.4   Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a15f1063",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-b8a535512542>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muntag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mgold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtag_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbrown\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtagged_sents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'editorial'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtag_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapply_tagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbrown\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtagged_sents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'editorial'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConfusionMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpretty_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msort_by_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_percents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 't2' is not defined"
     ]
    }
   ],
   "source": [
    "## For Chapter 4 Tagger\n",
    "\n",
    "def tag_list(tagged_sents):\n",
    "    return [tag for sent in tagged_sents for (word, tag) in sent]\n",
    "def apply_tagger(tagger, corpus):\n",
    "    return [tagger.tag(nltk.tag.untag(sent)) for sent in corpus]\n",
    "gold = tag_list(brown.tagged_sents(categories='editorial'))\n",
    "test = tag_list(apply_tagger(t2, brown.tagged_sents(categories='editorial')))\n",
    "cm = nltk.ConfusionMatrix(gold, test)\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d67ffe",
   "metadata": {},
   "source": [
    "## 3.5   Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e601cf3",
   "metadata": {},
   "source": [
    "# 4   Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936de3af",
   "metadata": {},
   "source": [
    "## 4.1   Entropy and Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c859e867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def entropy(labels):\n",
    "    freqdist = nltk.FreqDist(labels)\n",
    "    probs = [freqdist.freq(l) for l in freqdist]\n",
    "    return -sum(p * math.log(p,2) for p in probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "345e62c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0\n"
     ]
    }
   ],
   "source": [
    "print(entropy(['male', 'male', 'male', 'male']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b70fdace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8112781244591328\n"
     ]
    }
   ],
   "source": [
    "print(entropy(['male', 'female', 'male', 'male']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dce26635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(entropy(['female', 'male', 'female', 'male']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c73632cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8112781244591328\n"
     ]
    }
   ],
   "source": [
    "print(entropy(['female', 'female', 'male', 'female']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b28a8052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0\n"
     ]
    }
   ],
   "source": [
    "print(entropy(['female', 'female', 'female', 'female'])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03eac6e",
   "metadata": {},
   "source": [
    "# 5   Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bf7be9",
   "metadata": {},
   "source": [
    "## 5.1   Underlying Probabilistic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747ef57a",
   "metadata": {},
   "source": [
    "## 5.2   Zero Counts and Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d01bef8",
   "metadata": {},
   "source": [
    "## 5.3   Non-Binary Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d805f98a",
   "metadata": {},
   "source": [
    "## 5.4   The Naivete of Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c905c968",
   "metadata": {},
   "source": [
    "## 5.5   The Cause of Double-Counting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3ff6a3",
   "metadata": {},
   "source": [
    "# 6   Maximum Entropy Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c213c0",
   "metadata": {},
   "source": [
    "## 6.1   The Maximum Entropy Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcaf5ae",
   "metadata": {},
   "source": [
    "## 6.2   Maximizing Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bc493e",
   "metadata": {},
   "source": [
    "## 6.3   Generative vs Conditional Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fdc1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
